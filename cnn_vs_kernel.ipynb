{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba357c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraherar från data filen som kan hämtas online \n",
    "\n",
    "import tarfile\n",
    "import os\n",
    "\n",
    "archive_path = \"./data/cifar-10-python.tar.gz\"\n",
    "extract_path = \"./data\"\n",
    "\n",
    "# Extract\n",
    "with tarfile.open(archive_path, \"r:gz\") as tar:\n",
    "    tar.extractall(path=extract_path)\n",
    "\n",
    "\n",
    "print(\"Files in data folder after extraction:\", os.listdir(extract_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96c61ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f52e870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 5000\n",
      "Input dimensions (features): 3072\n",
      "Max svm pixel range after scaling: (-2.2089858, 2.6816778)\n"
     ]
    }
   ],
   "source": [
    "subset_size = 5000\n",
    "batch_size = 50\n",
    "\n",
    "# Normalisera (0, 255) -> (-1, 1)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Hämta data från ./data\n",
    "trainset_full = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=False, transform=transform)\n",
    "testset_full = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=False, transform=transform)\n",
    "\n",
    "# tar första subset_size st samples för att använda\n",
    "train_subset = torch.utils.data.Subset(trainset_full, range(subset_size))\n",
    "test_subset = torch.utils.data.Subset(testset_full, range(subset_size))  # same number for simplicity\n",
    "\n",
    "# batch uppdeling för cnn\n",
    "cnn_train = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "cnn_test = torch.utils.data.DataLoader(test_subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# SVM behöver feature vector, tensor 32x32x3 -> 3072 features\n",
    "def dataset_to_numpy(dataset):\n",
    "    X = np.array([np.array(img).flatten() for img, _ in dataset]) # data\n",
    "    y = np.array([label for _, label in dataset]) #labels\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = dataset_to_numpy(train_subset)\n",
    "X_test, y_test = dataset_to_numpy(test_subset)\n",
    "\n",
    "# normalisera data för svm\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test) # ingen data leak i testset\n",
    "\n",
    "print(\"Training samples:\", X_train.shape[0])\n",
    "print(\"Input dimensions (features):\", X_train.shape[1])\n",
    "print(\"Max svm pixel range after scaling:\", (X_train.min(), X_train.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c6e5ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN\n",
      "Running loss for epoch 1 : 194.05530071258545\n",
      "Finished training\n",
      "CNN test accuracy on 5000 samples:  40.5 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1) # padding ska behålla 32x32\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 10) # 3072 -> 10 klasser\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x)) # (N, 16, 32, 32)\n",
    "        x = self.pool(F.relu(self.conv2(x))) # 32x32 -> 16x16  (N, 32, 16, 16)\n",
    "        x = self.pool(x) # 16x16 -> 8x8  (N, 32, 8, 8)\n",
    "        x = x.view(batch_size, 32 * 8 * 8)  # (N, 32, 8, 8) -> (N, 2048) Härifrån vanligt NN\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss() # logsoftmax + NLLLoss\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001) # adam borde vara mycket snabbare än sgd\n",
    "\n",
    "# 1 epok\n",
    "print(\"Training CNN\")\n",
    "for epoch in range(1):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(cnn_train, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(\"Running loss for epoch\", epoch+1, \":\", running_loss)\n",
    "\n",
    "print(\"Finished training\")\n",
    "\n",
    "# Räkna accuracy på test_set\n",
    "correct, total = 0, 0\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in cnn_test:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "cnn_acc = 100 * correct / total\n",
    "print(\"CNN test accuracy on\" , subset_size, \"samples: \", cnn_acc, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fe0287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM\n",
      "SVM test accuracy on 5000 samples:  45.58 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# RBF kernel\n",
    "svm = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "\n",
    "\n",
    "# Träna och predict\n",
    "print(\"Training SVM\")\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "svm_acc = accuracy_score(y_test, y_pred) * 100\n",
    "\n",
    "print(\"SVM test accuracy on\" , subset_size, \"samples: \", svm_acc, \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
